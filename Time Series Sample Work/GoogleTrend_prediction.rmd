---
title: "Midterm Two- Prediction"
author: "Ryan Chui"
date: "Nov 15, 2016"
output: html_document
---
  
```{r}
library(TSA)
library(forecast)
library(ggplot2)
library(scales)

ts <- as.numeric(unlist(read.table("1DS.csv", quote="\"", comment.char="")))
ts.plot(ts)

# log10 computes common (i.e., base 10) logarithms
# log   computes natural logarithms by default
ts.log <- log(ts)

#Identification of best fit ARIMA model
# ARIMAfit <- auto.arima(diff(log(q1)))
# summary(ARIMAfit)

# Forecast No. of Cases using the best fit ARIMA model
# pred <- predict(ARIMAfit, n.ahead = 52)

"m1 <- arima(ts.log, order = c(1, 1, 1), seasonal = list(order = c(0, 0, 1), 
                                                        period = 52))
m2 <- arima(ts.log, order = c(1, 1, 2), 
            seasonal = list(order = c(0, 0, 1), period = 52)) 
m3 <- arima(ts.log, order = c(1, 1, 3), 
            seasonal = list(order = c(0, 0, 1), period = 52))
m4 = arima(ts.log, order = c(1, 1, 4), 
           seasonal = list(order = c(0, 0, 1), period = 52))
m5 = arima(ts.log, order = c(1, 1, 5), 
           seasonal = list(order = c(0, 0, 1), period = 52))"

m1 = arima(ts.log, order = c(0,1,1), 
           seasonal = list(order = c(0,1,1), period = 52))
m2 = arima(ts.log, order = c(0,1,2), 
           seasonal = list(order = c(0,1,1), period = 52))
m3 = arima(ts.log, order = c(0,1,3), 
           seasonal = list(order = c(0,1,1), period = 52))
m4 = arima(ts.log, order = c(0,1,4), 
           seasonal = list(order = c(0,1,1), period = 52))
m5 = arima(ts.log, order = c(0,1,5), 
           seasonal = list(order = c(0,1,1), period = 52))

#m4 = arima(ts.log, order = c(0,1,3), 
           # seasonal = list(order = c(0,1,1), period = 52))

# Base on AIC Criterion, we should pick m4
AIC(m1) 
AIC(m2) # -397.1538  
AIC(m3) 
AIC(m4) # -400.4293 <- Pick m4
AIC(m5)

# Base on BIC Criterion, we should pick m2
BIC(m1) 
BIC(m2) # -384.9544 <- Pick m2
BIC(m3)
BIC(m4) # -382.1302
BIC(m5)

par(mar = c(4,4,2,0))
tsdiag(m1,gof.lag	= 170)

len <- length(ts.log)
# we have a period of 52 so let's try to predict entire periods:
plot(ts, type = 'l')

computeCVmse <- function(order.totry, seasorder.totry){
  MSE <- numeric()
  for(k in 2:1){
    train.dt <-ts.log[1:(len - 52 * k)]
    test.dt <- ts.log[(len - 52 * k + 1):(len - 52 * (k - 1))]
    mod <- arima(train.dt, order = order.totry, seasonal = 
                   list(order = seasorder.totry, period = 52))
    fcast <- predict(mod, n.ahead = 52)
    MSE[k] <- mean((exp(fcast$pred) - exp(test.dt))^2)
  }
  return(MSE)
}

MSE1 <- computeCVmse(c(0,1,1), c(0, 1, 1)) # 13.78706 26.53101
MSE2 <- computeCVmse(c(0,1,2), c(0, 1, 1)) # 11.67564 26.56129 <- Set K = 1; pick m2
MSE3 <- computeCVmse(c(0,1,3), c(0, 1, 1)) # 11.88353 32.42124
MSE4 <- computeCVmse(c(0,1,4), c(0, 1, 1)) # 11.95002 23.04304 <- Set K = 2; Pick m4 LESS BIASED
MSE5 <- computeCVmse(c(0,1,5), c(0, 1, 1)) # 11.94706 22.69900


#### PART TO CREATE THE OUTPUT #################################################

### COMPARE the result between AIC and BIC criterion
### predictions <- exp(predict(m4, n.ahead = 52)$pred) <- under AIC Criterion
### DISPLAY FIRST 5 VALUES
### [1] 62.34071 61.35692 58.17968 70.55995 75.28463

### USE BIC Criterion!!
predictions <- exp(predict(m4, n.ahead = 52)$pred) # <- under BIC Criterion
### DISPLAY FIRST 5 VALUES
### [1] 62.28439 62.17879 59.88730 71.26626 75.48907

### predictions2 <- exp(predict(m4, n.ahead = 52)$pred) # <- under AIC Criterion
### DISPLAY FIRST 5 VALUES
### [1] 62.34071 61.35692 58.17968 70.55995 75.28463


### This align my assumption on analysis that BIC crtierion actually gives better result AIC criterion!!!!!

## Check: Does that make sense?
plot(1:(length(ts) + length(predictions)), c(ts, predictions), type = 'l', col = 1)
points((length(ts) + 1) : (length(ts) + length(predictions)), 
       predictions, type = 'l', col = 2)

write.table(predictions,
            sep = ",",
            col.names = FALSE,
            row.names = FALSE,
            file = "~/Downloads/Q1_Ryan_Chui_24061277.txt")

read.table("~/Downloads/Q1_Ryan_Chui_24061277.txt", sep = ",")
plot(as.numeric(unlist(read.table("~/Downloads/Q1_Ryan_Chui_24061277.txt", sep = ","))), type ="l")
```
  
```{r}
library(TSA)
library(forecast)
library(ggplot2)
library(scales)

ts <- as.numeric(unlist(read.table("2DS.csv", quote="\"", comment.char="")))
ts.plot(ts)

### query2 <- read.table("~/Downloads/2DS.csv", quote="\"", comment.char="")
### q2 <- ts(query2[,1],start = c(2011,11),frequency = 52)
# q2.hw = HoltWinters(q2)
# q2.predict = predict(q2.hw, n.ahead = 52)

# log10 computes common (i.e., base 10) logarithms
# log   computes natural logarithms by default
ts.log <- log(ts)
ts.log.d = diff(diff(ts))
ts.log.dd <- diff(ts.log.d, 52)

#Identification of best fit ARIMA model
#ARIMAfit <- auto.arima(log(q2), approximation=FALSE,trace=FALSE)
#summary(ARIMAfit)

#Forecast No. of Cases using the best fit ARIMA model
#pred <- predict(ARIMAfit, n.ahead = 52)

m1 = arima(ts.log, order = c(1, 0,1), 
            seasonal = list(order = c(0,1,1), period = 52))
m2 <- arima(ts.log, order = c(2, 0,1), 
            seasonal = list(order = c(0,1,1), period = 52))
m3 <- arima(ts.log, order = c(1, 0,3), 
            seasonal = list(order = c(0,1,1), period = 52))
m4 <- arima(ts.log, order = c(1, 0,4), 
            seasonal = list(order = c(0,1,1), period = 52))
m5 <- arima(ts.log, order = c(1, 0,5), 
            seasonal = list(order = c(0,1,1), period = 52))

AIC(m1) # -306.6561 
AIC(m2) # -304.697
AIC(m3) # -303.8442
AIC(m4) # -308.6436 <- Pick m4 under AIC criterion
AIC(m5) # -306.6656

BIC(m1)
# [1] -294.4311 <- Pick m1 under BIC criterion
BIC(m2)
# [1] -289.407
BIC(m3)
# [1] -285.5068
BIC(m4)
# [1] -287.2498
BIC(m5)
# [1] -282.2156

par(mar = c(4,4,2,0))
tsdiag(m1,gof.lag	= 170)

len <- length(ts.log)

computeCVmse <- function(order.totry, seasorder.totry){
  MSE <- numeric()
  for(k in 2:1){
    train.dt <-ts.log[1:(len - 52 * k)]
    test.dt <- ts.log[(len - 52 * k + 1):(len - 52 * (k - 1))]
    mod <- arima(train.dt, order = order.totry, seasonal = 
                   list(order = seasorder.totry, period = 52))
    fcast <- predict(mod, n.ahead = 52)
    MSE[k] <- mean((exp(fcast$pred) - exp(test.dt))^2)
  }
  return(MSE)
}


MSE1 <- computeCVmse(c(1, 0, 1), c(0, 1,1)) # 29.20956 192.84625
MSE2 <- computeCVmse(c(2, 0, 1), c(0, 1,1)) # 29.31158 296.01298
MSE3 <- computeCVmse(c(3, 0, 1), c(0, 1,1)) # 28.39949 121.14905 <- Set K = 2; Pick m3 LESS BIASED
MSE4 <- computeCVmse(c(4, 0, 1), c(0, 1,1)) # 27.78399 209.89442 <- Set K = 1; Pick m4 
MSE5 <- computeCVmse(c(5, 0, 1), c(0, 1,1)) # 31.17498 155.86186 

MSE1
MSE2
MSE3
MSE4
MSE5


#### PART TO CREATE THE OUTPUT #################################################

### Let's look at m1 and m4 ###
predictions <- exp(predict(m3, n.ahead = 52)$pred) 
##  [1] 86.21367 91.50265 68.99916 97.64885 94.68767 82.76178 44.69026 45.08872 74.85398 83.62105

## predictions2 <- exp(predict(m4, n.ahead = 52)$pred) for K = 1
## [1] 86.87936 90.03863 70.68765 98.75347 95.03111 82.93343 44.49629 44.54314 73.79031 82.14950

# Let's compare the actual "good" estimate!!
## q2.predict[,1]
## [1]  87.26165  92.11467  75.88733 102.69397 101.88225  91.66371  58.59794 60.83032  88.44422

# The predictions and predictions2 are really good estimate!!

## Check: Does that make sense?
plot(1:(length(ts) + length(predictions)), c(ts, predictions), type = 'l', col = 1)
points((length(ts) + 1) : (length(ts) + length(predictions)), predictions, type = 'l', col = 2)
# Great :) 

#write.table(predictions,
 #           sep = ",",
  #          col.names = FALSE,
   #         row.names = FALSE,
    #        file = "~/Downloads/Q2_Ryan_Chui_24061277.txt")

#read.table("~/Downloads/Q2_Ryan_Chui_24061277.txt", sep = ",")
#plot(as.numeric(unlist(read.table("~/Downloads/Q1_Ryan_Chui_24061277.txt", sep = ","))), type ="l")
```



